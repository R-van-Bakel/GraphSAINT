{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907cdc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "# from scipy.sparse import csr_matrix\n",
    "\n",
    "# https://stackoverflow.com/questions/52299420/scipy-csr-matrix-understand-indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948bd722",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myGraphSAINT(nn.Module):\n",
    "    def __init__(self, hidden_sizes):\n",
    "        super(myGraphSAINT, self).__init__()\n",
    "#         self.layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1], bias=False)\n",
    "#                                      for i in range(len(hidden_sizes)-1)])\n",
    "        self.weights = [\n",
    "            nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty((hidden_sizes[i], hidden_sizes[i+1])), gain=1/np.sqrt(6.0)))\n",
    "            for i in range(len(hidden_sizes)-1)\n",
    "        ]\n",
    "    \n",
    "    def forward(self, x, A):\n",
    "        for W in self.weights:\n",
    "            x = nn.functional.relu(A @ x @ W)\n",
    "        return x\n",
    "    \n",
    "    def sampleGraph(self, graph):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty((2, 3)), gain=1.0)))\n",
    "x = torch.rand((4,3))\n",
    "A = torch.eye(4)\n",
    "model = myGraphSAINT([3,10,3])\n",
    "print(model(x, A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c0d9c6",
   "metadata": {},
   "source": [
    "## Data loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dc6dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_train = np.load(\"./ppi/adj_train.npz\")\n",
    "\n",
    "# The data for the (symmetric) adjacency matrix\n",
    "data = adj_train[\"data\"]\n",
    "data = data.astype(int)\n",
    "indices = adj_train[\"indices\"]\n",
    "indptr = adj_train[\"indptr\"]\n",
    "shape = adj_train[\"shape\"]\n",
    "\n",
    "# # This is a less memory-efficient method to get the sparse torch adjacency matrix, that also requires SciPy\n",
    "# adj_matrix = csr_matrix((data, indices, indptr), shape=shape).toarray().astype(int)\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "# adj_matrix = torch.from_numpy(adj_matrix).to_sparse()\n",
    "\n",
    "# Change the SciPy csr format to torch format\n",
    "torch_first_indices = []\n",
    "for i in range(len(indptr)-1):\n",
    "    torch_first_indices += [i for ind in indices[indptr[i]:indptr[i+1]]]\n",
    "torch_first_indices = np.asarray(torch_first_indices)\n",
    "torch_indices = np.stack((torch_first_indices, indices))\n",
    "\n",
    "# The given shape for the ppi train set is much larger than the number of actual nodes in the set\n",
    "num_nodes = len(np.unique(torch_indices))\n",
    "shape_small = [num_nodes, num_nodes]\n",
    "\n",
    "# Create the adjacency matrix\n",
    "adj_matrix = torch.sparse_coo_tensor(indices=torch_indices, values=data, size=shape_small, dtype=torch.float64)\n",
    "\n",
    "# Calculate the node degrees\n",
    "degree = [0.0 for i in range(shape_small[0])]\n",
    "for i in torch_indices.T:\n",
    "    degree[i[0]] += 1\n",
    "    if i[1] == i[0]:\n",
    "        degree[i[0]] += 1\n",
    "inverse_degree = np.reciprocal(np.asarray(degree))\n",
    "\n",
    "# Calculate the normalized adjacency matrix\n",
    "norm_adj_data = inverse_degree[torch_indices[0]]*data.astype(float)\n",
    "# norm_adj_matrix = torch.sparse_coo_tensor(indices=torch_indices, values=norm_adj_data.astype(float), size=shape_small,\n",
    "#                                           dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d830648",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c549cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = 18\n",
    "\n",
    "# Calculate the sampling probablities\n",
    "p_nodes = [0.0 for i in range(shape_small[0])]\n",
    "for i, ind in enumerate(torch_indices[1]):\n",
    "    p_nodes[ind] += norm_adj_data[i]**2\n",
    "p_nodes = np.asarray(p_nodes)\n",
    "p_nodes = p_nodes/p_nodes.sum()\n",
    "\n",
    "# Get the edge probabilities\n",
    "# For the node sampler, the probability of an edge being sampled, is just to probability of both it's nodes being sampled\n",
    "# Note that for an edge connecting a node to itself, the probability of sampling it is just the probability of sampling the node\n",
    "self_loops = np.where(np.all(torch_indices == torch_indices[0,:], axis = 0)==True)\n",
    "p_edges = np.take(p_nodes, torch_indices)\n",
    "np.put(p_edges[1], self_loops, 1)\n",
    "p_edges = p_edges.prod(0)\n",
    "\n",
    "p_edge_matrix = torch.sparse_coo_tensor(indices=torch_indices, values=p_edges, size=shape_small, dtype=torch.float64)\n",
    "print(p_edge_matrix)\n",
    "\n",
    "\n",
    "def sample_nodes(num_nodes, budget, p_nodes):\n",
    "    # Sample\n",
    "    nodes_s = set(np.random.choice(np.arange(num_nodes), size=budget, p=p_nodes, replace=False))\n",
    "\n",
    "    # Connect the sampled nodes\n",
    "    edges_s = []\n",
    "    data_s = []\n",
    "    for i, edge in enumerate(torch_indices.transpose()):\n",
    "        if edge[0] in nodes_s and edge[1] in nodes_s:\n",
    "            edges_s.append(edge)\n",
    "    #         edges_s.append([orig2sub[edge[0]], orig2sub[edge[1]]])\n",
    "            data_s.append(data[i])\n",
    "    edges_s = np.asarray(edges_s).transpose()\n",
    "    data_s = np.asarray(data_s)\n",
    "\n",
    "    # Remove unconnected nodes (not connected to other nodes or themselves)\n",
    "    to_remove = set()\n",
    "    for node in nodes_s:\n",
    "        if node not in edges_s:\n",
    "            to_remove.add(node)\n",
    "            budget -= 1\n",
    "    nodes_s = nodes_s-to_remove\n",
    "    orig2sub = {ind : i for i, ind in enumerate(nodes_s)}\n",
    "    nodes_s_sub = {orig2sub[node] for node in nodes_s}\n",
    "    edges_s_sub = np.vectorize(orig2sub.get)(edges_s)\n",
    "\n",
    "    # Create the adjacency matrix of the sampled graph\n",
    "    adj_matrix_s = adj_matrix = torch.sparse_coo_tensor(indices=edges_s_sub, values=data_s, size=[budget, budget],\n",
    "                                                        dtype=torch.float64)\n",
    "    return adj_matrix_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a73b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample_weight_matrix(matrix, indices):\n",
    "#     return matrix[sorted(indices)][:, sorted(indices)]\n",
    "\n",
    "# W = torch.rand(shape_small)\n",
    "# W_batch = sample_weight_matrix(W, nodes_s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
