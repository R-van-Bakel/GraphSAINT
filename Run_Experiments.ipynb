{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907cdc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# https://stackoverflow.com/questions/52299420/scipy-csr-matrix-understand-indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948bd722",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myGraphSAINT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myGraphSAINT, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "    def sampleGraph(self, graph):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(3)\n",
    "model = myGraphSAINT()\n",
    "print(model(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c0d9c6",
   "metadata": {},
   "source": [
    "## Data loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dc6dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_train = np.load(\"./ppi/adj_train.npz\")\n",
    "\n",
    "# The data for the (symmetric) adjacency matrix\n",
    "data = adj_train[\"data\"]\n",
    "data = data.astype(int)\n",
    "indices = adj_train[\"indices\"]\n",
    "indptr = adj_train[\"indptr\"]\n",
    "shape = adj_train[\"shape\"]\n",
    "\n",
    "# # This is a less memory-efficient method to get the sparse torch adjacency matrix, that also requires SciPy\n",
    "# adj_matrix = csr_matrix((data, indices, indptr), shape=shape).toarray().astype(int)\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "# adj_matrix = torch.from_numpy(adj_matrix).to_sparse()\n",
    "\n",
    "# Change the SciPy csr format to torch format\n",
    "torch_first_indices = []\n",
    "for i in range(len(indptr)-1):\n",
    "    torch_first_indices += [i for ind in indices[indptr[i]:indptr[i+1]]]\n",
    "torch_first_indices = np.asarray(torch_first_indices)\n",
    "torch_indices = np.stack((torch_first_indices, indices))\n",
    "\n",
    "# The given shape for the ppi train set is much larger than the number of actual nodes in the set\n",
    "num_nodes = len(np.unique(torch_indices))\n",
    "shape_small = [num_nodes, num_nodes]\n",
    "\n",
    "# Create the adjacency matrix\n",
    "adj_matrix = torch.sparse_coo_tensor(indices=torch_indices, values=data, size=shape_small, dtype=torch.float64)\n",
    "\n",
    "# Calculate the node degrees\n",
    "degree = [0.0 for i in range(shape_small[0])]\n",
    "for i in torch_indices.T:\n",
    "    degree[i[0]] += 1\n",
    "    if i[1] == i[0]:\n",
    "        degree[i[0]] += 1\n",
    "inverse_degree = np.reciprocal(np.asarray(degree))\n",
    "\n",
    "# Calculate the normalized adjacency matrix\n",
    "norm_adj_data = inverse_degree[torch_indices[0]]*data.astype(float)\n",
    "# norm_adj_matrix = torch.sparse_coo_tensor(indices=torch_indices, values=norm_adj_data.astype(float), size=shape_small,\n",
    "#                                           dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d830648",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c549cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = 18\n",
    "\n",
    "# Calculate the sampling probablities\n",
    "p_nodes = [0.0 for i in range(shape_small[0])]\n",
    "for i, ind in enumerate(torch_indices[1]):\n",
    "    p_nodes[ind] += norm_adj_data[i]**2\n",
    "p_nodes = np.asarray(p_nodes)\n",
    "p_nodes = p_nodes/p_nodes.sum()\n",
    "\n",
    "# Sample \n",
    "nodes_s = set(np.random.choice(np.arange(shape_small[0]), size=budget, p=p_nodes, replace=False))\n",
    "\n",
    "# Connect the sampled nodes\n",
    "edges_s = []\n",
    "data_s = []\n",
    "for i, edge in enumerate(torch_indices.transpose()):\n",
    "    if edge[0] in nodes_s and edge[1] in nodes_s:\n",
    "        edges_s.append(edge)\n",
    "#         edges_s.append([orig2sub[edge[0]], orig2sub[edge[1]]])\n",
    "        data_s.append(data[i])\n",
    "edges_s = np.asarray(edges_s).transpose()\n",
    "data_s = np.asarray(data_s)\n",
    "\n",
    "# Remove unconnected nodes (not connected to other nodes or themselves)\n",
    "to_remove = set()\n",
    "for node in nodes_s:\n",
    "    if node not in edges_s:\n",
    "        to_remove.add(node)\n",
    "        budget -= 1\n",
    "nodes_s = nodes_s-to_remove\n",
    "orig2sub = {ind : i for i, ind in enumerate(nodes_s)}\n",
    "nodes_s_sub = {orig2sub[node] for node in nodes_s}\n",
    "edges_s_sub = np.vectorize(orig2sub.get)(edges_s)\n",
    "\n",
    "# Create the adjacency matrix of the sampled graph\n",
    "adj_matrix_s = adj_matrix = torch.sparse_coo_tensor(indices=edges_s_sub, values=data_s, size=[budget, budget],\n",
    "                                                    dtype=torch.float64)\n",
    "print(adj_matrix_s.to_dense())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
